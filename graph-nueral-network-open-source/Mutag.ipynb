{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_d5_th0.001_lr0.0001_fold0\n",
      "Accuracy on test set fold  0  :\n",
      "0.4347826\n",
      "st_d5_th0.001_lr0.0001_fold1\n",
      "Accuracy on test set fold  1  :\n",
      "0.5652174\n",
      "st_d5_th0.001_lr0.0001_fold2\n",
      "Accuracy on test set fold  2  :\n",
      "0.73913044\n",
      "st_d5_th0.001_lr0.0001_fold3\n",
      "Accuracy on test set fold  3  :\n",
      "0.6086956\n",
      "st_d5_th0.001_lr0.0001_fold4\n",
      "Accuracy on test set fold  4  :\n",
      "0.5217391\n",
      "st_d5_th0.001_lr0.0001_fold5\n",
      "Accuracy on test set fold  5  :\n",
      "0.82608694\n",
      "st_d5_th0.001_lr0.0001_fold6\n",
      "Accuracy on test set fold  6  :\n",
      "0.7826087\n",
      "st_d5_th0.001_lr0.0001_fold7\n",
      "Accuracy on test set fold  7  :\n",
      "0.73913044\n",
      "st_d5_th0.001_lr0.0001_fold8\n",
      "Accuracy on test set fold  8  :\n",
      "0.8695652\n",
      "st_d5_th0.001_lr0.0001_fold9\n",
      "Accuracy on test set fold  9  :\n",
      "0.8695652\n",
      "Mean accuracy from all folds: 0.6956521\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gnn.gnn_utils as gnn_utils\n",
    "from gnn.GNN import GNN as GraphNetwork\n",
    "import gnn.load as ld\n",
    "\n",
    "\n",
    "##### GPU & stuff config\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "#############   DATA LOADING    ##################################################\n",
    "# function to get a fold\n",
    "def getFold(fold):\n",
    "    # load dataset\n",
    "    train = ld.loadmat(\"./Data/Mutag/multi\" + str(fold))\n",
    "    train = train['multi' + str(fold)]\n",
    "\n",
    "    ############ training set #############\n",
    "\n",
    "    ret_train = gnn_utils.set_load_mutag(\"train\", train)\n",
    "\n",
    "    ###########validation#####################\n",
    "\n",
    "    ret_val = gnn_utils.set_load_mutag(\"validation\", train)\n",
    "\n",
    "    ########### test #####################\n",
    "\n",
    "    ret_test = gnn_utils.set_load_mutag(\"test\", train)\n",
    "\n",
    "    return ret_train, ret_val, ret_test\n",
    "\n",
    "\n",
    "# create the 10-fold in order to train on 10-fold cross validation\n",
    "tr, val, ts = [], [], []\n",
    "for fold in range(1, 11):\n",
    "    a, b, c = getFold(fold)\n",
    "    tr.append(a)\n",
    "    val.append(b)\n",
    "    ts.append(c)\n",
    "\n",
    "\n",
    "EPSILON = 0.00000001\n",
    "\n",
    "@tf.function()\n",
    "def loss_fcn(target,output):\n",
    "    target = tf.cast(target,tf.float32)\n",
    "    output = tf.maximum(output, EPSILON, name=\"Avoiding_explosions\")  # to avoid explosions\n",
    "    xent = -tf.reduce_sum(target * tf.math.log(output), 1)\n",
    "    lo = tf.reduce_mean(xent)\n",
    "    return lo\n",
    "\n",
    "@tf.function()\n",
    "def metric(output, target):\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(target, 1))\n",
    "    metric = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return metric\n",
    "\n",
    "\n",
    "# set input and output dim, the maximum number of iterations, the number of epochs and the optimizer\n",
    "\n",
    "# set parameter\n",
    "threshold = 0.001\n",
    "learning_rate = 0.0001\n",
    "state_dim = 5\n",
    "max_it = 50\n",
    "num_epoch = 500\n",
    "output_dim = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testacc = []\n",
    "\n",
    "for fold in range(0, 10):\n",
    "\n",
    "    param = \"st_d\" + str(state_dim) + \"_th\" + str(threshold) + \"_lr\" + str(learning_rate)\n",
    "    completeName = param + 'log.txt'\n",
    "    param = param + \"_fold\" + str(fold)\n",
    "    print(param)\n",
    "\n",
    "\n",
    "    # retrieve input, arcnode, nodegraph and target for training set\n",
    "    inp = tr[fold][0]\n",
    "    input_dim = len(inp[0][0])\n",
    "\n",
    "    arcnode = tr[fold][1]\n",
    "    labels = tr[fold][4]\n",
    "    nodegraph = tr[fold][2]\n",
    "\n",
    "    # retrieve input, arcnode, nodegraph and target for validation set\n",
    "    inp_val = val[fold][0]\n",
    "    arcnode_val = val[fold][1]\n",
    "    labels_val = val[fold][4]\n",
    "    nodegraph_val = val[fold][2]\n",
    "    \n",
    "    inp = inp[0]\n",
    "\n",
    "    arcnode = arcnode[0]\n",
    "\n",
    "    nodegraph = nodegraph[0]\n",
    "\n",
    "    inp_val = inp_val[0]\n",
    "\n",
    "    arcnode_val = arcnode_val[0]\n",
    "\n",
    "    nodegraph_val = nodegraph_val[0]\n",
    "\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    model = GraphNetwork(input_dim, state_dim, output_dim,                             \n",
    "                             hidden_state_dim = 15, hidden_output_dim = 10,\n",
    "                             ArcNode=arcnode,NodeGraph=nodegraph,threshold=threshold)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer,loss_fcn)\n",
    "\n",
    "    # train GNN, and validate every 2 epochs, (early stopping)\n",
    "    count = 0\n",
    "    valid_best = None\n",
    "    patience = 0\n",
    "    \n",
    "    for j in range(0, num_epoch):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = model.train_step(inp.astype(np.float32),labels)\n",
    "\n",
    "            #early stopping\n",
    "            if count % 2 == 0:\n",
    "                out_val = model.predict(inp_val.astype(np.float32), arcnode_val,nodegraph_val)\n",
    "                loss_value_val = loss_fcn(labels_val,out_val)\n",
    "                \n",
    "                if count == 0:\n",
    "                    valid_best = loss_value_val\n",
    "\n",
    "                if loss_value_val < valid_best:\n",
    "                    valid_best = loss_value_val\n",
    "                    patience = 0\n",
    "                else:\n",
    "                    patience += 1\n",
    "\n",
    "                if patience > 5:\n",
    "                    print(\"Early stopping...\")\n",
    "                    break\n",
    "                    \n",
    "                count = count + 1\n",
    "\n",
    "    # retrieve input, arcnode, nodegraph and target for test set\n",
    "    inp_test = ts[fold][0]\n",
    "    arcnode_test = ts[fold][1]\n",
    "    labels_test = ts[fold][4]\n",
    "    nodegraph_test = ts[fold][2]\n",
    "    \n",
    "    inp_test = inp_test[0]\n",
    "\n",
    "    arcnode_test = arcnode_test[0]\n",
    "\n",
    "    nodegraph_test = nodegraph_test[0]\n",
    "\n",
    "    \n",
    "    print('Accuracy on test set fold ', fold, ' :')\n",
    "\n",
    "    # evaluate on the test set fold\n",
    "    \n",
    "    out_test = model.predict(inp_test, arcnode_test, nodegraph_test)\n",
    "    metric_value_test = metric(labels_test,out_test)\n",
    "    testacc.append(metric_value_test.numpy())\n",
    "    print(metric_value_test.numpy())\n",
    "#     with open(os.path.join('tmp/', completeName), \"a\") as file:\n",
    "#         file.write('Accuracy on test set fold ' + str(fold) + ' :')\n",
    "#         file.write(str(evel) + '\\n')\n",
    "#         file.write('\\n')\n",
    "#         file.close()\n",
    "\n",
    "# mean accuracy on the 10-fold\n",
    "mean_acc = np.mean(np.asarray(testacc))\n",
    "print('Mean accuracy from all folds:', mean_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
